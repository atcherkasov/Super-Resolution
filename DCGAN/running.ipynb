{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Discriminator and Generator implementation from DCGAN paper\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 64 x 64\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 64 x 64\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 64, 64\n",
    "    noise_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n",
    "    gen = Generator(noise_dim, in_channels, 8)\n",
    "    z = torch.randn((N, noise_dim, 1, 1))\n",
    "    assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n",
    "\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 4781012.93it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 52502.46it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1360325.65it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 23811.69it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "Epoch [0/5] Batch 0/469                   Loss D: 0.6985, loss G: 0.7566\n",
      "Epoch [0/5] Batch 100/469                   Loss D: 0.0014, loss G: 6.8743\n",
      "Epoch [0/5] Batch 200/469                   Loss D: 0.0001, loss G: 8.9374\n",
      "Epoch [0/5] Batch 300/469                   Loss D: 0.0001, loss G: 9.7391\n",
      "Epoch [0/5] Batch 400/469                   Loss D: 0.0000, loss G: 9.8700\n",
      "Epoch [1/5] Batch 0/469                   Loss D: 0.0000, loss G: 10.7901\n",
      "Epoch [1/5] Batch 100/469                   Loss D: 0.0000, loss G: 10.8128\n",
      "Epoch [1/5] Batch 200/469                   Loss D: 0.0000, loss G: 11.4608\n",
      "Epoch [1/5] Batch 300/469                   Loss D: 0.0000, loss G: 10.5933\n",
      "Epoch [1/5] Batch 400/469                   Loss D: 0.0000, loss G: 11.9883\n",
      "Epoch [2/5] Batch 0/469                   Loss D: 0.0000, loss G: 12.1453\n",
      "Epoch [2/5] Batch 100/469                   Loss D: 0.0000, loss G: 12.0411\n",
      "Epoch [2/5] Batch 200/469                   Loss D: 0.0000, loss G: 12.6784\n",
      "Epoch [2/5] Batch 300/469                   Loss D: 0.0000, loss G: 12.4259\n",
      "Epoch [2/5] Batch 400/469                   Loss D: 0.0000, loss G: 12.9250\n",
      "Epoch [3/5] Batch 0/469                   Loss D: 0.0001, loss G: 11.9212\n",
      "Epoch [3/5] Batch 100/469                   Loss D: 0.0000, loss G: 12.6762\n",
      "Epoch [3/5] Batch 200/469                   Loss D: 0.0000, loss G: 13.3094\n",
      "Epoch [3/5] Batch 300/469                   Loss D: 0.0000, loss G: 13.5268\n",
      "Epoch [3/5] Batch 400/469                   Loss D: 0.0000, loss G: 13.3061\n",
      "Epoch [4/5] Batch 0/469                   Loss D: 0.0000, loss G: 13.5583\n",
      "Epoch [4/5] Batch 100/469                   Loss D: 0.0000, loss G: 13.7938\n",
      "Epoch [4/5] Batch 200/469                   Loss D: 0.0000, loss G: 12.5736\n",
      "Epoch [4/5] Batch 300/469                   Loss D: 0.0000, loss G: 13.5739\n",
      "Epoch [4/5] Batch 400/469                   Loss D: 0.0000, loss G: 14.1742\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training of DCGAN network on MNIST dataset with Discriminator\n",
    "and Generator imported from models.py\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from model import Discriminator, Generator, initialize_weights\n",
    "\n",
    "# Hyperparameters etc.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 5\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# If you train on MNIST, remember to set channels_img to 1\n",
    "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms,\n",
    "                       download=True)\n",
    "\n",
    "# comment mnist above and uncomment below if train on CelebA\n",
    "#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake.detach()).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:32], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:32], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.0 at http://localhost:6008/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
