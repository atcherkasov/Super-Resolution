{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Discriminator and Generator implementation from DCGAN paper\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 32 x 32\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "#             self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 4, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
    "#             self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 4, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 32 x 32\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 32, 32\n",
    "    noise_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n",
    "    gen = Generator(noise_dim, in_channels, 8)\n",
    "    z = torch.randn((N, noise_dim, 1, 1))\n",
    "    assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 228\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.data_dir = data_dir        # example: 'dataset/train'\n",
    "        self.transform = transform    \n",
    "        self.labeled_objects = []   # в формате (<путь до файла>, <номер класса>)\n",
    "        for dirname, dirs, files in os.walk(self.data_dir):\n",
    "            for filename in files:\n",
    "                fname_without_ext, extension = os.path.splitext(filename)\n",
    "                self.labeled_objects.append((join(dirname, filename),\n",
    "                                             int(fname_without_ext)))   \n",
    "\n",
    "        self.labeled_objects = shuffle(self.labeled_objects, \n",
    "                                       random_state=RANDOM_SEED)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labeled_objects[idx][0]\n",
    "        image = Image.open(img_name)\n",
    "        label = torch.tensor([self.labeled_objects[idx][1]])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from os.path import join\n",
    "\n",
    "# root=\"../../DATA/archive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# train_dataset = MyDataset(root + 'DIV2K_train_HR', transforms)\n",
    "# # val_dataset = MyDataset(root + 'DIV2K_valid_HR', transforms)\n",
    "\n",
    "# obg_num = 11\n",
    "\n",
    "\n",
    "# img, label = train_dataset[obg_num]\n",
    "# img, label = val_dataset[obg_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just very simple checks\n",
    "# assert isinstance(train_dataset[0], tuple)\n",
    "# assert len(train_dataset[0]) == 2\n",
    "# print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 32\n",
    "CHANNELS_IMG = 3\n",
    "NOISE_DIM = 32\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), interpolation=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(root + 'DIV2K_train_HR', transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs_b64/real\")\n",
    "writer_fake = SummaryWriter(f\"logs_b64/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    # enumerate\n",
    "    # batch_idx\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, NOISE_DIM, 3).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake.detach()).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:32], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:32], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 168337408/169001437 [00:19<00:00, 11411987.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f42954c01d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "169009152it [00:30, 11411987.72it/s]                               "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(trainset[1000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
